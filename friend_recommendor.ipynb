{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>experience</th>\n",
       "      <th>interest-1</th>\n",
       "      <th>interest-2</th>\n",
       "      <th>interest-3</th>\n",
       "      <th>linkedIn</th>\n",
       "      <th>github</th>\n",
       "      <th>proficiency-1</th>\n",
       "      <th>proficiency-2</th>\n",
       "      <th>about-me</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>George</td>\n",
       "      <td>3</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>I am passionate in data science would like a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Suresh</td>\n",
       "      <td>2</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Full Stack web development</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>350</td>\n",
       "      <td>20</td>\n",
       "      <td>Octave</td>\n",
       "      <td>MEAN stack</td>\n",
       "      <td>I am flexible with both deep learning and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Geeta</td>\n",
       "      <td>5</td>\n",
       "      <td>Internet of things</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>App development</td>\n",
       "      <td>800</td>\n",
       "      <td>40</td>\n",
       "      <td>Arduino</td>\n",
       "      <td>Python</td>\n",
       "      <td>I am really into real world applications of Io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Suneeta\\t</td>\n",
       "      <td>1</td>\n",
       "      <td>Frontend development</td>\n",
       "      <td>App development</td>\n",
       "      <td>Backend development</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>MERN stack</td>\n",
       "      <td>Flutter</td>\n",
       "      <td>I am person with more taste in web development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Girish</td>\n",
       "      <td>10</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>Python</td>\n",
       "      <td>C++</td>\n",
       "      <td>I am passionate in data science would like a c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       name  experience            interest-1  \\\n",
       "0      1     George           3         Deep Learning   \n",
       "1      2     Suresh           2         Deep Learning   \n",
       "2      3      Geeta           5    Internet of things   \n",
       "3      4  Suneeta\\t           1  Frontend development   \n",
       "4      5     Girish          10         Deep Learning   \n",
       "\n",
       "                   interest-2                   interest-3  linkedIn  github  \\\n",
       "0            Machine Learning  Natural Language Processing       500      50   \n",
       "1  Full Stack web development  Natural Language Processing       350      20   \n",
       "2             Computer Vision              App development       800      40   \n",
       "3             App development          Backend development       100       5   \n",
       "4            Machine Learning  Natural Language Processing      1000     100   \n",
       "\n",
       "  proficiency-1 proficiency-2  \\\n",
       "0        Python             R   \n",
       "1        Octave    MEAN stack   \n",
       "2       Arduino        Python   \n",
       "3    MERN stack       Flutter   \n",
       "4        Python           C++   \n",
       "\n",
       "                                            about-me  \n",
       "0  I am passionate in data science would like a c...  \n",
       "1  I am flexible with both deep learning and the ...  \n",
       "2  I am really into real world applications of Io...  \n",
       "3  I am person with more taste in web development...  \n",
       "4  I am passionate in data science would like a c...  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('friends.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       George\n",
       "1       Suresh\n",
       "2        Geeta\n",
       "3    Suneeta\\t\n",
       "4       Girish\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all integer values to string so that they can be concattinated later in the program\n",
    "for column in df.columns:\n",
    "    df[column]=df[column].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George',\n",
       " '3',\n",
       " 'Deep Learning',\n",
       " 'Machine Learning',\n",
       " 'Natural Language Processing',\n",
       " '500',\n",
       " '50',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'I am passionate in data science would like a carrier in the same. I am in the 5th semester of engineering. I like data science because of the way it has changed the world. I am passionate in data science would like a carrier in the same. I am in the 5th semester of engineering. I like data science because of the way it has changed the world. I am passionate in data science would like a carrier in the same. I am in the 5th semester of engineering. I like data science because of the way it has changed the world.']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 'George'\n",
    "userspecs = list(np.array(df[df['name']==user])[0])[1:]\n",
    "userspecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to combine the values of the different columns into a single string\n",
    "def combined_specs(row):\n",
    "    return(row['experience']+\" \"+row['interest-1']+\" \"+row['interest-2']+\" \"+row['interest-3']+\" \"+row['linkedIn']+\" \"+row['github']+\" \"+row['proficiency-1']+\" \"+row['proficiency-2'])\n",
    "\n",
    "#apply the function to each row in the dataframe to store the combined strings into a new column called combimed_specs\n",
    "df['combined_specs']=df.apply(combined_specs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.4330127  0.08703883 0.         0.80064077]\n",
      " [0.4330127  1.         0.07537784 0.3125     0.41602515]\n",
      " [0.08703883 0.07537784 1.         0.30151134 0.0836242 ]\n",
      " [0.         0.3125     0.30151134 1.         0.06933752]\n",
      " [0.80064077 0.41602515 0.0836242  0.06933752 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#convert a collection of data into count_matrix\n",
    "count_matrix=CountVectorizer()\n",
    "count_matrix=count_matrix.fit_transform(df['combined_specs'])\n",
    "\n",
    "#convert a the count_matrix into cosine similarity matrix\n",
    "cosine_sim_mat=cosine_similarity(count_matrix)\n",
    "print(cosine_sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.0000000000000002),\n",
       " (4, 0.8006407690254358),\n",
       " (1, 0.43301270189221935),\n",
       " (2, 0.08703882797784893),\n",
       " (3, 0.0)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends = cos_mat[df.index[df['name']==user]][0].tolist()\n",
    "friends_list = []\n",
    "for i,j in enumerate(friends):\n",
    "    friends_list.append((i,j));\n",
    "friends_list.sort(key=lambda x:x[1],reverse=True)\n",
    "friends_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girish\n",
      "Suresh\n",
      "Geeta\n"
     ]
    }
   ],
   "source": [
    "# find top 3 friends\n",
    "for i,j in friends_list[1:4]:\n",
    "    print(df.iloc[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sumukh Raju\n",
      "[nltk_data]     Bhat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about-me</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am passionate in data science would like a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am flexible with both deep learning and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am really into real world applications of Io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am person with more taste in web development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am passionate in data science would like a c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            about-me\n",
       "0  I am passionate in data science would like a c...\n",
       "1  I am flexible with both deep learning and the ...\n",
       "2  I am really into real world applications of Io...\n",
       "3  I am person with more taste in web development...\n",
       "4  I am passionate in data science would like a c..."
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df[['about-me']]\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=True):\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [lemmatizer.lemmatize(word) if '#' not in word else word\n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    passionate data science would like carrier th ...\n",
       "1    flexible deep learning full stack web developm...\n",
       "2    really real world application iot computer vis...\n",
       "3    person taste web development frontend backend ...\n",
       "4    passionate data science would like carrier th ...\n",
       "Name: about-me, dtype: object"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['about-me'] = df['about-me'].apply(clean_tweet)\n",
    "df['about-me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(df['about-me']).toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 10\n",
    "\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "      <th>Topic 5 words</th>\n",
       "      <th>Topic 5 weights</th>\n",
       "      <th>Topic 6 words</th>\n",
       "      <th>Topic 6 weights</th>\n",
       "      <th>Topic 7 words</th>\n",
       "      <th>Topic 7 weights</th>\n",
       "      <th>Topic 8 words</th>\n",
       "      <th>Topic 8 weights</th>\n",
       "      <th>Topic 9 words</th>\n",
       "      <th>Topic 9 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development</td>\n",
       "      <td>4.1</td>\n",
       "      <td>science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>6.1</td>\n",
       "      <td>science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>full</td>\n",
       "      <td>6.1</td>\n",
       "      <td>science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>science</td>\n",
       "      <td>14.1</td>\n",
       "      <td>science</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>world</td>\n",
       "      <td>0.1</td>\n",
       "      <td>world</td>\n",
       "      <td>0.1</td>\n",
       "      <td>world</td>\n",
       "      <td>0.1</td>\n",
       "      <td>like</td>\n",
       "      <td>6.1</td>\n",
       "      <td>world</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>3.1</td>\n",
       "      <td>world</td>\n",
       "      <td>0.1</td>\n",
       "      <td>data</td>\n",
       "      <td>14.1</td>\n",
       "      <td>world</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also</td>\n",
       "      <td>2.1</td>\n",
       "      <td>like</td>\n",
       "      <td>0.1</td>\n",
       "      <td>like</td>\n",
       "      <td>0.1</td>\n",
       "      <td>like</td>\n",
       "      <td>0.1</td>\n",
       "      <td>iot</td>\n",
       "      <td>6.1</td>\n",
       "      <td>like</td>\n",
       "      <td>0.1</td>\n",
       "      <td>web</td>\n",
       "      <td>3.1</td>\n",
       "      <td>like</td>\n",
       "      <td>0.1</td>\n",
       "      <td>data_science</td>\n",
       "      <td>14.1</td>\n",
       "      <td>like</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good_app</td>\n",
       "      <td>2.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>world</td>\n",
       "      <td>3.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>3.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>like</td>\n",
       "      <td>14.1</td>\n",
       "      <td>web_development</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frontend_backend</td>\n",
       "      <td>2.1</td>\n",
       "      <td>web</td>\n",
       "      <td>0.1</td>\n",
       "      <td>web</td>\n",
       "      <td>0.1</td>\n",
       "      <td>web</td>\n",
       "      <td>0.1</td>\n",
       "      <td>real</td>\n",
       "      <td>3.1</td>\n",
       "      <td>web</td>\n",
       "      <td>0.1</td>\n",
       "      <td>flexible_deep</td>\n",
       "      <td>3.1</td>\n",
       "      <td>web</td>\n",
       "      <td>0.1</td>\n",
       "      <td>would</td>\n",
       "      <td>7.1</td>\n",
       "      <td>web</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frontend</td>\n",
       "      <td>2.1</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1</td>\n",
       "      <td>really</td>\n",
       "      <td>3.1</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1</td>\n",
       "      <td>stack_web</td>\n",
       "      <td>3.1</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1</td>\n",
       "      <td>passionate</td>\n",
       "      <td>7.1</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efficiently_good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>application_iot</td>\n",
       "      <td>3.1</td>\n",
       "      <td>development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>stack</td>\n",
       "      <td>3.1</td>\n",
       "      <td>development</td>\n",
       "      <td>0.1</td>\n",
       "      <td>passionate_data</td>\n",
       "      <td>7.1</td>\n",
       "      <td>development</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efficiently</td>\n",
       "      <td>2.1</td>\n",
       "      <td>world_</td>\n",
       "      <td>0.1</td>\n",
       "      <td>world_</td>\n",
       "      <td>0.1</td>\n",
       "      <td>world_</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sensor_iot</td>\n",
       "      <td>3.1</td>\n",
       "      <td>world_</td>\n",
       "      <td>0.1</td>\n",
       "      <td>fledged</td>\n",
       "      <td>3.1</td>\n",
       "      <td>world_</td>\n",
       "      <td>0.1</td>\n",
       "      <td>engineering_like</td>\n",
       "      <td>7.1</td>\n",
       "      <td>world_</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>taste</td>\n",
       "      <td>2.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sensor</td>\n",
       "      <td>3.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>fledged_computer</td>\n",
       "      <td>3.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.1</td>\n",
       "      <td>engineering</td>\n",
       "      <td>7.1</td>\n",
       "      <td>computer_science</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taste_web</td>\n",
       "      <td>2.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.1</td>\n",
       "      <td>computer_vision</td>\n",
       "      <td>3.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.1</td>\n",
       "      <td>flexible</td>\n",
       "      <td>3.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.1</td>\n",
       "      <td>changed_world</td>\n",
       "      <td>7.1</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic 0 words Topic 0 weights     Topic 1 words Topic 1 weights  \\\n",
       "0       development             4.1           science             0.1   \n",
       "1              good             2.1             world             0.1   \n",
       "2              also             2.1              like             0.1   \n",
       "3          good_app             2.1   web_development             0.1   \n",
       "4  frontend_backend             2.1               web             0.1   \n",
       "5          frontend             2.1              good             0.1   \n",
       "6  efficiently_good             2.1       development             0.1   \n",
       "7       efficiently             2.1            world_             0.1   \n",
       "8             taste             2.1  computer_science             0.1   \n",
       "9         taste_web             2.1          computer             0.1   \n",
       "\n",
       "      Topic 2 words Topic 2 weights     Topic 3 words Topic 3 weights  \\\n",
       "0           science             0.1           science             0.1   \n",
       "1             world             0.1             world             0.1   \n",
       "2              like             0.1              like             0.1   \n",
       "3   web_development             0.1   web_development             0.1   \n",
       "4               web             0.1               web             0.1   \n",
       "5              good             0.1              good             0.1   \n",
       "6       development             0.1       development             0.1   \n",
       "7            world_             0.1            world_             0.1   \n",
       "8  computer_science             0.1  computer_science             0.1   \n",
       "9          computer             0.1          computer             0.1   \n",
       "\n",
       "     Topic 4 words Topic 4 weights     Topic 5 words Topic 5 weights  \\\n",
       "0         computer             6.1           science             0.1   \n",
       "1             like             6.1             world             0.1   \n",
       "2              iot             6.1              like             0.1   \n",
       "3            world             3.1   web_development             0.1   \n",
       "4             real             3.1               web             0.1   \n",
       "5           really             3.1              good             0.1   \n",
       "6  application_iot             3.1       development             0.1   \n",
       "7       sensor_iot             3.1            world_             0.1   \n",
       "8           sensor             3.1  computer_science             0.1   \n",
       "9  computer_vision             3.1          computer             0.1   \n",
       "\n",
       "      Topic 6 words Topic 6 weights     Topic 7 words Topic 7 weights  \\\n",
       "0              full             6.1           science             0.1   \n",
       "1  computer_science             3.1             world             0.1   \n",
       "2               web             3.1              like             0.1   \n",
       "3   web_development             3.1   web_development             0.1   \n",
       "4     flexible_deep             3.1               web             0.1   \n",
       "5         stack_web             3.1              good             0.1   \n",
       "6             stack             3.1       development             0.1   \n",
       "7           fledged             3.1            world_             0.1   \n",
       "8  fledged_computer             3.1  computer_science             0.1   \n",
       "9          flexible             3.1          computer             0.1   \n",
       "\n",
       "      Topic 8 words Topic 8 weights     Topic 9 words Topic 9 weights  \n",
       "0           science            14.1           science             0.1  \n",
       "1              data            14.1             world             0.1  \n",
       "2      data_science            14.1              like             0.1  \n",
       "3              like            14.1   web_development             0.1  \n",
       "4             would             7.1               web             0.1  \n",
       "5        passionate             7.1              good             0.1  \n",
       "6   passionate_data             7.1       development             0.1  \n",
       "7  engineering_like             7.1            world_             0.1  \n",
       "8       engineering             7.1  computer_science             0.1  \n",
       "9     changed_world             7.1          computer             0.1  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda21ed2f8b40f042aa951aad37ec7eb1a5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
